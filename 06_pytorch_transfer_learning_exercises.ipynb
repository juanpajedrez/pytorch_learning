{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/06_pytorch_transfer_learning_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNqPNlYylluR"
      },
      "source": [
        "# 06. PyTorch Transfer Learning Exercises\n",
        "\n",
        "Welcome to the 06. PyTorch Transfer Learning exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
        "\n",
        "## Resources and solutions\n",
        "\n",
        "* These exercises/solutions are based on [section 06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
        "\n",
        "**Solutions:** \n",
        "\n",
        "Try to complete the code below *before* looking at these.\n",
        "\n",
        "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ueLolShyFqs).\n",
        "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/06_pytorch_transfer_learning_exercise_solutions.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwmoMhW8IqSu"
      },
      "source": [
        "## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels. \n",
        "* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n",
        "* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Find curr_dir\n",
        "import os\n",
        "\n",
        "# Setting up os.chdir to current path\n",
        "os.chdir(os.path.abspath(os.getcwd()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqtAWBUJgaF1",
        "outputId": "14cc75f3-e109-4e84-c941-2598df3557b3"
      },
      "outputs": [],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !move pytorch-deep-learning/going_modular .\n",
        "    !rmdir /s /q pytorch-deep-learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from going_modular.going_modular import data_setup, engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O10_T_xSKJlf",
        "outputId": "fd30e756-e542-4b2b-d974-1ed38451fecf"
      },
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzg3TaSKLAh"
      },
      "source": [
        "### Get data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_CNQ4rKPmg",
        "outputId": "a1364d91-3afa-4401-94cb-94e4df837f06"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGaMWWaoKQlM"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNIQNEQVKVXu"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njd5lHTcKW23",
        "outputId": "fbc224df-8243-4e7b-90cd-49adc000fd47"
      },
      "outputs": [],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's check one iteration of our training dataloader\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "train_features.shape, train_labels.shape\n",
        "\n",
        "print(f\"Batch of train features shape: {train_features.shape}\") # shape of image data (features\n",
        "print(f\"Batch of train labels shape: {train_labels.shape}\")     # shape of labels data\n",
        "\n",
        "#Let's select a random index and plot the image\n",
        "import random\n",
        "rand_idx = random.randint(0, len(train_features)-1)\n",
        "fig, ax = plt.subplots(figsize = (6, 8))\n",
        "\n",
        "# Permute the image from (C, H, W) to (H, W, C)\n",
        "ax.imshow(train_features[rand_idx].permute(1, 2, 0))\n",
        "ax.set_title(class_names[train_labels[rand_idx]])\n",
        "ax.axis(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciw2DiRHKaSE"
      },
      "source": [
        "### Get and prepare a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "6e25b4bb0d254191a793696a0f4f00ce",
            "37424313e66f474da42cfe1b512f09df",
            "58fd00f6a9114192a4fa757c1f669bff",
            "f115ea4b5fad4bb1910fca49ed3da8a1",
            "e8eba8e353e940ff9287929e41e4d656",
            "bc33539914a947ee89c271f10ea6a2bb",
            "6e03cb60fab94b7e92ce16c8178922dd",
            "5d464254c31d4516899643112fa0e958",
            "06df3ad4b7454556a43b6d61640b12f8",
            "0bdc7325c839439589a16c88876d6bd5",
            "873a483782894789bf0dee546a1b2d50"
          ]
        },
        "id": "snUuRXd8Kdk5",
        "outputId": "eac2a1e6-5607-437e-90b5-41639d17e5a8"
      },
      "outputs": [],
      "source": [
        "# Setup the model with pretrained weights and send it to the target device \n",
        "model_0_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_0 = torchvision.models.efficientnet_b0(weights=model_0_weights).to(device)\n",
        "#model_0 # uncomment to output (it's very long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbRhGvy_KeVL"
      },
      "outputs": [],
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model_0.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1-6xV3ZKeSX"
      },
      "outputs": [],
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model_0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True), \n",
        "    torch.nn.Linear(in_features=1280, \n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)\n",
        "model_0.classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQFaXX8CKePi"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exxU79eaKeM6"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ae21171f17de45d895ab7a319dade609",
            "f9c60d9c0aed49faa993fd865fb09174",
            "755366e3f75e44c2b7a79bce78d77d11",
            "4a05e8d965124327a2329cf9e1eec984",
            "fe93ec079b384ac38a6f4d0e505431ff",
            "88dea77f1bcf44ffb69654515ee34f54",
            "2678a567b0414e1d9cfbfc2ecf5ffd30",
            "ce621be138a84f33b24c05b2d9cfd5f0",
            "1fa41d239a3a4845904434d057476a75",
            "f4827c6e36a1463fb0c82347f64230a2",
            "cea8f9c48bd8429998352a090173f537"
          ]
        },
        "id": "ComVkVtuKeKG",
        "outputId": "6d43205a-4e9f-4627-999a-40d07380cd58"
      },
      "outputs": [],
      "source": [
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer \n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "model_0_results = engine.train(model=model_0,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model_0_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFS4lE_IKyE_"
      },
      "source": [
        "### Make predictions on the entire test dataset with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwZuCluFu375"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "#Set the model.eval()\n",
        "model_0.eval()\n",
        "\n",
        "# Get them ready to iterate\n",
        "y_test_true_total = []\n",
        "y_test_preds_total = []\n",
        "\n",
        "#This came in handy in the next excercise\n",
        "y_test_probs_total = []\n",
        "X_test_sample_total = []\n",
        "\n",
        "# Start with torch inference mode\n",
        "with torch.inference_mode():\n",
        "    #Iterate across all X, y for test_dataloader\n",
        "    for batch, (X, y) in tqdm(enumerate(test_dataloader), desc=\"Iterating across test batches...\", total=len(test_dataloader)):\n",
        "        X: torch.Tensor\n",
        "        y: torch.Tensor\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        #Store X samples for later use\n",
        "        X_test_sample_total.extend(X.to(device))\n",
        "\n",
        "        # Obtain y_logits from it\n",
        "        y_logits = model_0(X).to(device)\n",
        "\n",
        "        #Obtain y_probs and extend them\n",
        "        y_probs = torch.softmax(y_logits, dim=1)\n",
        "        \n",
        "        #Obtain y_preds\n",
        "        y_preds = y_probs.argmax(dim = 1)\n",
        "\n",
        "        #Extend them respectively\n",
        "        y_test_true_total.extend(y.tolist())\n",
        "        y_test_preds_total.extend(y_preds.tolist())\n",
        "\n",
        "        #Extend the test probability for the specific predicted label found\n",
        "        y_test_probs_total.extend(y_probs.max(dim=1).values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_test_true_total)\n",
        "print(y_test_preds_total)\n",
        "print(y_test_probs_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Select random sample from X_test_sample_total\n",
        "random_idx = random.randint(0, len(X_test_sample_total)-1)\n",
        "X_sample = X_test_sample_total[random_idx]\n",
        "y_true = y_test_true_total[random_idx]\n",
        "y_pred = y_test_preds_total[random_idx]\n",
        "y_prob = y_test_probs_total[random_idx]\n",
        "\n",
        "print(f\"X_sample shape: {X_sample.shape}\")\n",
        "print(f\"True class: {class_names[y_true]}, Predicted class: {class_names[y_pred]}, Probability: {y_prob:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb2bQ1b5K2WP"
      },
      "source": [
        "### Make a confusion matrix with the test preds and the truth labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I2jpYAcM07s"
      },
      "source": [
        "Need the following libraries to make a confusion matrix:\n",
        "* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n",
        "* mlxtend - http://rasbt.github.io/mlxtend/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKYZGWuK2P8",
        "outputId": "88c33b26-0b76-42d7-8a27-fb3073b1fc3f"
      },
      "outputs": [],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOYVew4xMxgI",
        "outputId": "d3b393b8-09c3-46f7-c799-2f91ee4d30e6"
      },
      "outputs": [],
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend \n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5LU9-5Xu7dP"
      },
      "outputs": [],
      "source": [
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Obtain the confusion matrix\n",
        "cm = confusion_matrix(y_target=y_test_true_total,\n",
        "                      y_predicted=y_test_preds_total,\n",
        "                      binary=False)\n",
        "fig, ax = plot_confusion_matrix(cm)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlStPo-gbrF"
      },
      "source": [
        "## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
        "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
        "* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n",
        "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n",
        "\n",
        "You'll want to:\n",
        "* Create a DataFrame with sample, label, prediction, pred prob\n",
        "* Sort DataFrame by correct (does label == prediction)\n",
        "* Sort DataFrame by pred prob (descending)\n",
        "* Plot the top 5 \"most wrong\" image predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHtMeYHuvDwy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "data = {\n",
        "    \"sample\": [x for x in range(len(y_test_true_total))],\n",
        "    \"y_true\": y_test_true_total,\n",
        "    \"y_pred\": y_test_preds_total,\n",
        "    \"y_prob\": y_test_probs_total\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(data, index=data[\"sample\"])\n",
        "\n",
        "#Select subset of results where y_true != y_pred\n",
        "df_incorrect = df_results[df_results[\"y_true\"] != df_results[\"y_pred\"]]\n",
        "\n",
        "# Sort by probability of the predicted class (y_prob) descending\n",
        "df_incorrect_sorted = df_incorrect.sort_values(by=\"y_prob\", ascending=False)\n",
        "df_incorrect_sorted.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now let's plot the top 5 incorrect predictions\n",
        "num_to_plot = 5\n",
        "\n",
        "# Inverse transform to undo the transformations applied to the images\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
        "    std=[1/0.229, 1/0.224, 1/0.255]\n",
        ")\n",
        "\n",
        "for i in range(num_to_plot):\n",
        "\n",
        "    # Let's get the sample index\n",
        "    sample_idx = df_incorrect_sorted.index[i]\n",
        "\n",
        "    # Let's retrieve the sample data\n",
        "    X_sample = X_test_sample_total[sample_idx]\n",
        "\n",
        "    #Inverse normalize the image\n",
        "    X_sample = inv_normalize(X_sample)\n",
        "\n",
        "    #Let's get the true label, predicted label and predicted probability\n",
        "    y_true = y_test_true_total[sample_idx]\n",
        "    y_pred = y_test_preds_total[sample_idx]\n",
        "    y_prob = y_test_probs_total[sample_idx]\n",
        "\n",
        "    # Plot the incorrect sample\n",
        "    fig, ax = plt.subplots(figsize=(6, 8))\n",
        "    ax.imshow(X_sample.permute(1, 2, 0).cpu())\n",
        "    ax.set_title(f\"True: {class_names[y_true]}, Pred: {class_names[y_pred]}, Prob: {y_prob:.3f}\")\n",
        "    ax.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IvuTskxgjaw"
      },
      "source": [
        "## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n",
        "* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C16glgVFglmG"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of pizza/steak/sushi\n",
        "\n",
        "#Let's select a random image from image_path\n",
        "import random\n",
        "\n",
        "#Let's get all image file paths\n",
        "image_file_paths = list(image_path.rglob(\"*/*.jpg\"))\n",
        "\n",
        "#Select a random image file path\n",
        "random_image_path = random.choice(image_file_paths)\n",
        "random_image_path\n",
        "\n",
        "# Now let's load and preprocess the image\n",
        "from PIL import Image\n",
        "\n",
        "# Load the Image\n",
        "img = Image.open(random_image_path).convert(\"RGB\")\n",
        "\n",
        "# Preprocess the image\n",
        "img_trans = simple_transform(img).unsqueeze(0).to(device) # add batch dimension and send to device\n",
        "\n",
        "# Set model to eval and use inference mode\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    y_logits = model_0(img_trans)\n",
        "    y_probs = torch.softmax(y_logits, dim=1)\n",
        "    y_pred = y_probs.argmax(dim=1)\n",
        "    y_prob = y_probs.max().item()\n",
        "\n",
        "# Plot the image with prediction\n",
        "fig, ax = plt.subplots(figsize=(6, 8))\n",
        "ax.imshow(img)\n",
        "ax.set_title(f\"Pred: {class_names[y_pred]}, Prob: {y_prob:.3f}\")\n",
        "ax.axis(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clA_KmihVYyA"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of not pizza/steak/sushi\n",
        "\n",
        "img_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT0i1O3NJNlEr6EWkU-RSXAU-7cBFhzNdDMdw&s\" # Image of bandeja paisa\n",
        "\n",
        "# Let's load the image from the URL using requests\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Let;s write the image to data folder with name bandeja_paisa.jpg\n",
        "with open(image_path / \"bandeja_paisa.jpg\", \"wb\") as f:\n",
        "    request = requests.get(img_url)\n",
        "    f.write(request.content)\n",
        "print(f\"Image written to {image_path / 'bandeja_paisa.jpg'}\")\n",
        "\n",
        "# Load the Image\n",
        "img = Image.open(image_path / \"bandeja_paisa.jpg\")\n",
        "img = img.convert(\"RGB\")\n",
        "\n",
        "# Preprocess the image\n",
        "img_trans = simple_transform(img).unsqueeze(0).to(device) # add batch dimension and send to device\n",
        "\n",
        "# Set the model to eval and inference mode\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    y_logits = model_0(img_trans)\n",
        "    y_probs = torch.softmax(y_logits, dim=1)\n",
        "    y_pred = y_probs.argmax(dim=1)\n",
        "    y_prob = y_probs.max().item()\n",
        "\n",
        "# Plot the image with prediction\n",
        "fig, ax = plt.subplots(figsize=(6, 8))\n",
        "ax.imshow(img)\n",
        "ax.set_title(f\"Pred: {class_names[y_pred]}, Prob: {y_prob:.3f}\")\n",
        "ax.axis(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzvi8GprgmJ0"
      },
      "source": [
        "## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n",
        "\n",
        "* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_0 = torchvision.models.efficientnet_b0(weights=weights).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIKg53Jna-Rt"
      },
      "outputs": [],
      "source": [
        "# TODO: Recreate a new model \n",
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model_0.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Let's set up the classifier layer again\n",
        "output_shape = len(class_names)\n",
        "model_0.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True), \n",
        "    nn.Linear(in_features=1280, \n",
        "              out_features=output_shape, # same number of output units as our number of classes\n",
        "              bias=True)\n",
        ")\n",
        "model_0.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhGT9igPgoF5"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the model for 10 epochs\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Let's train the model for 10 epochs\n",
        "epochs = 10\n",
        "model_0_results_10_epochs = engine.train(model=model_0,\n",
        "                               train_dataloader=train_dataloader,\n",
        "                               test_dataloader=test_dataloader,\n",
        "                               optimizer=optimizer,\n",
        "                               loss_fn=loss_fn,\n",
        "                               epochs=epochs,\n",
        "                               device=device)\n",
        "model_0_results_10_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oRrWPZTgoqL"
      },
      "source": [
        "## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n",
        "* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyMMnUbgvw2"
      },
      "source": [
        "### Get 20% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_fdu5m2eKT9",
        "outputId": "121c61f3-f505-4302-b3b9-8b8bae5b5e1d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / image_data_zip_path, \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / image_data_zip_path)\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir_20_percent = image_path / \"train\"\n",
        "test_dir_20_percent = image_path / \"test\"\n",
        "\n",
        "train_dir_20_percent, test_dir_20_percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQj7eFdSe4Fv"
      },
      "source": [
        "### Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEG_k785e7Jw"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82x7LnQJe7H5",
        "outputId": "342fd4e7-0656-495a-aee0-0d23be130438"
      },
      "outputs": [],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "                                                                                                     test_dir=test_dir_20_percent,\n",
        "                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                                                     batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROl77sKfIOd"
      },
      "source": [
        "### Get a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHWNZ6yDvpR8"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_0 = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# Model 0 Classifier setup\n",
        "output_shape = len(class_names)\n",
        "model_0.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True), \n",
        "    nn.Linear(in_features=1280,\n",
        "                out_features=output_shape, # same number of output units as our number of classes\n",
        "                bias=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqffJfOIfp3T"
      },
      "source": [
        "### Train a model with 20% of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXpYOYeTvp7a"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Let's train the model for 10 epochs\n",
        "epochs = 10\n",
        "model_0_results_20_percent = engine.train(\n",
        "    model=model_0,\n",
        "    train_dataloader=train_dataloader_20_percent,\n",
        "    test_dataloader=test_dataloader_20_percent,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    epochs=epochs,\n",
        "    device=device)\n",
        "model_0_results_20_percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibj4UPjRgvly"
      },
      "source": [
        "## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n",
        "* You'll have to change the size of the classifier layer to suit our problem.\n",
        "* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n",
        "  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FQ8tL7El7eO"
      },
      "outputs": [],
      "source": [
        "# TODO \n",
        "weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "model_2 = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "\n",
        "# Model 0 Classifier setup\n",
        "model_2.classifier"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNXgsMoZLpp/LR5qPnNG65Z",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "06_pytorch_transfer_learning_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06df3ad4b7454556a43b6d61640b12f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdc7325c839439589a16c88876d6bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa41d239a3a4845904434d057476a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2678a567b0414e1d9cfbfc2ecf5ffd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37424313e66f474da42cfe1b512f09df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc33539914a947ee89c271f10ea6a2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_6e03cb60fab94b7e92ce16c8178922dd",
            "value": "100%"
          }
        },
        "4a05e8d965124327a2329cf9e1eec984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4827c6e36a1463fb0c82347f64230a2",
            "placeholder": "​",
            "style": "IPY_MODEL_cea8f9c48bd8429998352a090173f537",
            "value": " 5/5 [00:31&lt;00:00,  5.81s/it]"
          }
        },
        "58fd00f6a9114192a4fa757c1f669bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d464254c31d4516899643112fa0e958",
            "max": 21444401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06df3ad4b7454556a43b6d61640b12f8",
            "value": 21444401
          }
        },
        "5d464254c31d4516899643112fa0e958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e03cb60fab94b7e92ce16c8178922dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e25b4bb0d254191a793696a0f4f00ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37424313e66f474da42cfe1b512f09df",
              "IPY_MODEL_58fd00f6a9114192a4fa757c1f669bff",
              "IPY_MODEL_f115ea4b5fad4bb1910fca49ed3da8a1"
            ],
            "layout": "IPY_MODEL_e8eba8e353e940ff9287929e41e4d656"
          }
        },
        "755366e3f75e44c2b7a79bce78d77d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce621be138a84f33b24c05b2d9cfd5f0",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa41d239a3a4845904434d057476a75",
            "value": 5
          }
        },
        "873a483782894789bf0dee546a1b2d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88dea77f1bcf44ffb69654515ee34f54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae21171f17de45d895ab7a319dade609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c60d9c0aed49faa993fd865fb09174",
              "IPY_MODEL_755366e3f75e44c2b7a79bce78d77d11",
              "IPY_MODEL_4a05e8d965124327a2329cf9e1eec984"
            ],
            "layout": "IPY_MODEL_fe93ec079b384ac38a6f4d0e505431ff"
          }
        },
        "bc33539914a947ee89c271f10ea6a2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce621be138a84f33b24c05b2d9cfd5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea8f9c48bd8429998352a090173f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8eba8e353e940ff9287929e41e4d656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f115ea4b5fad4bb1910fca49ed3da8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc7325c839439589a16c88876d6bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_873a483782894789bf0dee546a1b2d50",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 61.8MB/s]"
          }
        },
        "f4827c6e36a1463fb0c82347f64230a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c60d9c0aed49faa993fd865fb09174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dea77f1bcf44ffb69654515ee34f54",
            "placeholder": "​",
            "style": "IPY_MODEL_2678a567b0414e1d9cfbfc2ecf5ffd30",
            "value": "100%"
          }
        },
        "fe93ec079b384ac38a6f4d0e505431ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
